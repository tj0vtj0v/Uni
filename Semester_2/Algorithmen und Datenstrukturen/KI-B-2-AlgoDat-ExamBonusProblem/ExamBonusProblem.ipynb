{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eca039a152585b1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Exam Bonus Problem - Decision Tree Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a50597-5fa2-4756-8511-8255f6f99a69",
   "metadata": {},
   "source": [
    "Professor: Prof. Dr. Patrick  Glauner<br>\n",
    "Participant: 22211158 -> Noah Tjorven Burdorf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16deff148b2c855e",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Remark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3e802-1fc0-48c3-9ed7-1e1807e370cf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This submission is additional to another one in which I participated.<br>\n",
    "My main goal is to get potential feedback to my algorithm which differs severely from the collaborated one.\n",
    "\n",
    "Regarding the intent of the submission the overhead is minimized and the visualisation is drastically reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6857640f4aa1804",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37358513-a620-459e-a87d-1f34b7ba96a7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "There are a few things to be mentioned regarding the dataset and visualisation.\n",
    "This project is divided in a few files, but for simplicity we view it all as a simple script.\n",
    "Used libraries for this solution are pprint, math and random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40031de3-cc90-4837-aae0-7bba4c1e4ca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.403321Z",
     "start_time": "2024-06-08T07:39:44.381082200Z"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a7815-8e59-4205-969c-909acf935fe2",
   "metadata": {},
   "source": [
    "### The Dataset\n",
    "The dataset is a simple list containing a dictionary with the keys \"result\" and \"dependencies\".<br>\n",
    "Here the dependencies are representing a table, a method for reading a csv for data acquisition can be found in the other submission.\n",
    "The data are from the lecture where we initially got to know the DT_LEARNING function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67679efb-228d-4b77-80a4-5d8eb8f50db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.404528100Z",
     "start_time": "2024-06-08T07:39:44.386857500Z"
    }
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"dependencies\": {\"visible\": 0, \"distance\": \"< 10\", \"armed\": 0, }, \"result\": True},\n",
    "    {\"dependencies\": {\"visible\": 0, \"distance\": \"< 10\", \"armed\": 1, }, \"result\": False},\n",
    "    {\"dependencies\": {\"visible\": 0, \"distance\": \"10 - 20\", \"armed\": 0}, \"result\": False},\n",
    "    {\"dependencies\": {\"visible\": 0, \"distance\": \"10 - 20\", \"armed\": 1}, \"result\": False},\n",
    "    {\"dependencies\": {\"visible\": 0, \"distance\": \"> 20\", \"armed\": 0, }, \"result\": False},\n",
    "    {\"dependencies\": {\"visible\": 0, \"distance\": \"> 20\", \"armed\": 1, }, \"result\": False},\n",
    "    {\"dependencies\": {\"visible\": 1, \"distance\": \"< 10\", \"armed\": 0, }, \"result\": True},\n",
    "    {\"dependencies\": {\"visible\": 1, \"distance\": \"< 10\", \"armed\": 1, }, \"result\": True},\n",
    "    {\"dependencies\": {\"visible\": 1, \"distance\": \"10 - 20\", \"armed\": 0}, \"result\": True},\n",
    "    {\"dependencies\": {\"visible\": 1, \"distance\": \"10 - 20\", \"armed\": 1}, \"result\": True},\n",
    "    {\"dependencies\": {\"visible\": 1, \"distance\": \"> 20\", \"armed\": 0, }, \"result\": False},\n",
    "    {\"dependencies\": {\"visible\": 1, \"distance\": \"> 20\", \"armed\": 1, }, \"result\": False}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8525264b-b461-4ada-979e-00dc62afd0bb",
   "metadata": {},
   "source": [
    "The attributes are additionally stored in another list of dictionaries, consisting of the keys \"name\" and \"values\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dfb9475-c0b7-478e-9b7c-d7ced495a0fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.405108700Z",
     "start_time": "2024-06-08T07:39:44.390381400Z"
    }
   },
   "outputs": [],
   "source": [
    "attributes = [\n",
    "    {\"name\": \"visible\", \"values\": [0, 1]},\n",
    "    {\"name\": \"distance\", \"values\": [\"< 10\", \"10 - 20\", \"> 20\"]},\n",
    "    {\"name\": \"armed\", \"values\": [0, 1]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c315cdbb29d20",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### The Visualisation\n",
    "The function to plot, or more exactly print the decision tree is a provisional. An advanced tree is part of the other submission.\n",
    "An additional overview over the received data is provided by the pretty print library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "279e5d37-6861-4904-ab7c-d4792f81fd22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.405108700Z",
     "start_time": "2024-06-08T07:39:44.394953500Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_tree(data: dict | bool, depth: int, decision):\n",
    "    if type(data) is bool:\n",
    "        print((depth - 1) * \"    \" + \"|-- \" + str(decision) + bool(depth) * \" -> \" + str(data))\n",
    "        return\n",
    "    print((depth - 1) * \"    \" + '|-- ' + str(decision) + bool(depth) * \" -- \" + data[\"attribute\"])\n",
    "    data.pop(\"attribute\")\n",
    "    for key, value in data.items():\n",
    "        print_tree(value, depth + 1, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca9bf4-41b8-48dd-8c3b-2ce528439bf6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## The Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff85253b-ff54-4f20-a131-16349604a46d",
   "metadata": {},
   "source": [
    "### Implementation of the predefined methods\n",
    "First of all we take a look at the implementation of the three methods \"DT_LEANING\", \"PLURALITY_VAL\" and \"IMPORTANCE\".<br>\n",
    "A few functionalities are outsourced, but all methods are named intuitively, and are going to be explained in the course of this documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82198ce1-fb1d-4207-bc86-abdc5279f6aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.405619600Z",
     "start_time": "2024-06-08T07:39:44.400563800Z"
    }
   },
   "outputs": [],
   "source": [
    "def DT_LEARNING(examples: list[dict], attributes: list[dict], parent_examples: list[dict]) -> bool | dict:\n",
    "    \"\"\"recursive decision tree learning algorithm as discussed in the lecture\"\"\"\n",
    "    tree = {}\n",
    "\n",
    "    if not examples:\n",
    "        return PLURALITY_VAL(parent_examples)\n",
    "    elif _same_classification(examples):\n",
    "        return examples[0][\"result\"]\n",
    "    elif not attributes:\n",
    "        return PLURALITY_VAL(examples)\n",
    "    else:\n",
    "        attribute = _argmax_importance(attributes, examples)\n",
    "        tree[\"attribute\"] = attribute[\"name\"]\n",
    "        attributes.remove(attribute)\n",
    "    for value in attribute[\"values\"]:\n",
    "        child_examples = _determine_child_examples(attribute[\"name\"], value, examples)\n",
    "\n",
    "        tree[value] = DT_LEARNING(child_examples, attributes.copy(), examples)\n",
    "\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e100b2-be23-4d82-b5c7-bb527838a6ba",
   "metadata": {},
   "source": [
    "This function is as explained in the lecture, extended with formalized python syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57abebd-5b3b-4fde-b034-28ea943e3107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.407633200Z",
     "start_time": "2024-06-08T07:39:44.405108700Z"
    }
   },
   "outputs": [],
   "source": [
    "def PLURALITY_VAL(examples: list[dict]) -> bool:\n",
    "    \"\"\"calculates the most common result in the examples\"\"\"\n",
    "    true_examples = _count_true_examples(examples)\n",
    "    return true_examples > len(examples) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cba6c0-bf1a-46c1-9428-239042d6bf5f",
   "metadata": {},
   "source": [
    "Implementation of the plurality functionality. As said the used function will be explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a5fbcc-e73b-4a1b-af8d-05efca749f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.469231100Z",
     "start_time": "2024-06-08T07:39:44.407633200Z"
    }
   },
   "outputs": [],
   "source": [
    "def IMPORTANCE(attribute: dict, examples: list[dict]) -> float:\n",
    "    \"\"\"computes the importance of an attribute\"\"\"\n",
    "    D = _count_true_examples(examples) / len(examples)\n",
    "    information_gain = _binary_entropy(D)\n",
    "\n",
    "    for value in attribute[\"values\"]:\n",
    "        occurrence, positive_occurrence = _attribute_occurrence(examples, attribute[\"name\"], value)\n",
    "        remainder = occurrence / len(examples) * _binary_entropy(positive_occurrence / occurrence)\n",
    "        information_gain -= remainder\n",
    "\n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2be643-4643-4a8e-954a-8539a19cda62",
   "metadata": {},
   "source": [
    "The information-gain is calculated with the least amount of lines of code, without compromising the readability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d7b5e-dd77-4c2d-848e-7258c92a8d5d",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1afd3-3de5-4e96-882b-151b04d570c5",
   "metadata": {},
   "source": [
    "First there is the \"_count_true_examples\" method, which like the name suggests, counts all examples with a positive result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5925932a-0ecd-4ba3-bf72-1f3f164496b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.469231100Z",
     "start_time": "2024-06-08T07:39:44.413734800Z"
    }
   },
   "outputs": [],
   "source": [
    "def _count_true_examples(examples: list[dict]) -> int:\n",
    "    \"\"\"counts the examples with the output value true\"\"\"\n",
    "    true_count = 0\n",
    "    for example in examples:\n",
    "        if example[\"result\"]:\n",
    "            true_count += 1\n",
    "\n",
    "    return true_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac680fe-1c3a-4a13-9218-742eb6c1c789",
   "metadata": {},
   "source": [
    "Secondly we consider the \"_binary_entropy\" which is calculated following the formula, except for the input-values zero and one, where the value zero is returned, avoiding an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b5ebfd-1900-41a4-9314-8b8870af9f07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.470230900Z",
     "start_time": "2024-06-08T07:39:44.415746100Z"
    }
   },
   "outputs": [],
   "source": [
    "def _binary_entropy(q: float) -> float:\n",
    "    \"\"\"calculates the binary entropy of input q\"\"\"\n",
    "    return 0 if q == 1 or q == 0 else -(q * math.log2(q) + (1 - q) * math.log2(1 - q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9203541e-a407-4ccc-95ce-f2535df7925e",
   "metadata": {},
   "source": [
    "After that we have the function \"_attribute_occurrence\", returning a tuple consisting of the total occurrence of an attribute and the corresponding occurrences with a positive result in the examples.\n",
    "This was combined to prevent repetition and a higher runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4365267-1cb6-4486-831b-2afc21e5304a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.470230900Z",
     "start_time": "2024-06-08T07:39:44.419765800Z"
    }
   },
   "outputs": [],
   "source": [
    "def _attribute_occurrence(examples: list[dict], attribute_name: str, attribute_value: any) -> tuple[int, int]:\n",
    "    \"\"\"returns the overall and positive occurrence of an attribute in the given examples\"\"\"\n",
    "    occurrence = 0\n",
    "    positive_occurrence = 0\n",
    "\n",
    "    for example in examples:\n",
    "        if example[\"dependencies\"][attribute_name] == attribute_value:\n",
    "\n",
    "            occurrence += 1\n",
    "            if example[\"result\"]:\n",
    "                positive_occurrence += 1\n",
    "\n",
    "    return occurrence, positive_occurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91a8c6-71e0-4993-bb8d-80e13207a827",
   "metadata": {},
   "source": [
    "Now we had to implement \"_same_classification\" which checks if all examples have the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167b8f5c-51e6-4bbd-a979-2f337b88c1c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.470230900Z",
     "start_time": "2024-06-08T07:39:44.423295Z"
    }
   },
   "outputs": [],
   "source": [
    "def _same_classification(examples: list[dict]) -> bool:\n",
    "    \"\"\"returns if all examples lead to the same result\"\"\"\n",
    "    classification = examples[0][\"result\"]\n",
    "    for example in examples:\n",
    "        if example[\"result\"] != classification:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facfc424-ed4e-42f8-b230-da3c59fe9fe3",
   "metadata": {},
   "source": [
    "In order to recurse the \"DT_LEARNING\" we have to reduce the examples according to our new attribute, which is done as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eaaa282-d5e7-4a79-8770-92c4c8bd5692",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.470230900Z",
     "start_time": "2024-06-08T07:39:44.427060400Z"
    }
   },
   "outputs": [],
   "source": [
    "def _determine_child_examples(attribute_name: dict, attribute_value: str, examples: list[dict]) -> list[dict]:\n",
    "    \"\"\"filters examples for an specific attribute value\"\"\"\n",
    "    child_examples = []\n",
    "\n",
    "    for example in examples:\n",
    "        if example[\"dependencies\"][attribute_name] == attribute_value:\n",
    "            child_examples.append(example)\n",
    "\n",
    "    return child_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9cad9-b2a3-4360-b4d1-003de38efabb",
   "metadata": {},
   "source": [
    "The last unexplored step of this algorithm is the argmax function of the IMPORTANCE, named according to its functionality \"_argmax_importance\".<br>\n",
    "It loops over all attributes and calculates the number and name of the attributes affecting the result the most. In case of a tie it breaks it randomly, which is the only use for the random function in this program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5183a73-6810-46d4-8988-79bf331115e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.470230900Z",
     "start_time": "2024-06-08T07:39:44.430633200Z"
    }
   },
   "outputs": [],
   "source": [
    "def _argmax_importance(attributes: list[dict], examples: list[dict]) -> dict:\n",
    "    \"\"\"equivalent of an argmax function for the IMPORTANCE function\"\"\"\n",
    "    maximum_importance = 0\n",
    "    maximum_attributes = []\n",
    "\n",
    "    for attribute in attributes:\n",
    "        importance = IMPORTANCE(attribute, examples)\n",
    "\n",
    "        if importance > maximum_importance:\n",
    "            maximum_importance = importance\n",
    "            maximum_attributes = [attribute]\n",
    "\n",
    "        elif importance == maximum_importance:\n",
    "            maximum_attributes.append(attribute)\n",
    "\n",
    "    return random.choice(maximum_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e170a87-67a1-4727-a018-9125d3693e03",
   "metadata": {},
   "source": [
    "## The Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4a8e9d-2a46-4bdc-973d-7e43aed1f8fb",
   "metadata": {},
   "source": [
    "With the output of the DT_LEANING algorithm, we can create a simple tree.\n",
    "In this case it is not pretty but does the job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b3f1a04-7c9c-4827-96c8-198305413bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T07:39:44.471736300Z",
     "start_time": "2024-06-08T07:39:44.434317500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-- distance\n",
      "|-- < 10 -- visible\n",
      "    |-- 0 -- armed\n",
      "        |-- 0 -> True\n",
      "        |-- 1 -> False\n",
      "    |-- 1 -> True\n",
      "|-- 10 - 20 -- visible\n",
      "    |-- 0 -> False\n",
      "    |-- 1 -> True\n",
      "|-- > 20 -> False\n",
      "\n",
      "\n",
      "{'10 - 20': {0: False, 1: True},\n",
      " '< 10': {0: {0: True, 1: False}, 1: True},\n",
      " '> 20': False,\n",
      " 'attribute': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "result = DT_LEARNING(examples, attributes, examples)\n",
    "\n",
    "print_tree(result.copy(), 0, \"\")\n",
    "print(\"\\n\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15d889-27df-44c2-81f6-575ecd2a3102",
   "metadata": {},
   "source": [
    "First there is my own visualisation, with the attribute named on top, and the values called out on each branch. Followed by the child decision tree and eventually the classification, labeled with an additional \"->\".<br>\n",
    "Because of the awful visualisation, I added a pretty-printed version of the raw output right behind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af08e5e4d099c09",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9547d2-ce29-4df7-98d9-bc3f0c4315d3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Ideas can be influenced by the other approach.<br>\n",
    "There were no external sources utilized beside the lecture material.<br>\n",
    "I emphasize that no AI was used, and all the code - except the DT_LEARNING - is entirely self written."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
